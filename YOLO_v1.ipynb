{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=16.64s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.63s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import yolo_utils\n",
    "import yolo_constants as yc\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "#Structure of output tensor (label) for every cell is: \n",
    "#[588 dimensional vector] with repeating (class1,...,class20,box1-params, box2-params)\n",
    "def createOutputTensor(imgList):\n",
    "    output = np.zeros((len(imgList), yc.CELL_NUMBER_HORI * yc.CELL_NUMBER_VERT * yc.NUM_PARAMS_LABEL))\n",
    "    imgIndex = -1\n",
    "    for img in imgList:\n",
    "        #print(img['file_name'])\n",
    "        #shutil.copy(\"D:\\\\FH\\\\Master\\\\Fachseminar\\\\images\\\\train2017\\\\\" + img['file_name'], \".\\\\images\\\\train2017\\\\\" + img['file_name'])\n",
    "        \n",
    "        imgIndex += 1\n",
    "        for row in range(yc.CELL_NUMBER_VERT):\n",
    "            for col in range(yc.CELL_NUMBER_HORI):\n",
    "                clsValues = list()\n",
    "                boxParams = list()\n",
    "                \n",
    "                #Every cell can only detect one object. \n",
    "                yolo_utils.getClassValuesForCell(img, clsValues, (row, col))\n",
    "\n",
    "                #Adding box-coordinates\n",
    "                yolo_utils.getBoxParamsForCell(img, boxParams, (row, col))\n",
    "                \n",
    "                #class values are added once to the output tensor\n",
    "                for i in range(len(yc.CLASSES)):\n",
    "                    output[imgIndex, row*yc.PARAMS_PER_ROW_LABEL + col*yc.NUM_PARAMS_LABEL + i] = clsValues[i]\n",
    "                    \n",
    "                #for every bounding box the parameters have to be added to the output tensor\n",
    "                for i in range(yc.COUNT_BOUNDING_BOXES):\n",
    "                    for j in range(4):\n",
    "                        #the label only has 4 box parameters. The confidence score is calculated in the loss function\n",
    "                        output[imgIndex, row*yc.PARAMS_PER_ROW_LABEL + col*yc.NUM_PARAMS_LABEL + yc.COUNT_CLASSES + i*4 + j] = boxParams[i][j]\n",
    "                \n",
    "    outputDataset = tf.data.Dataset.from_tensor_slices(output)\n",
    "    return outputDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATHS = yolo_utils.getImageAdresses(yc.IMAGE_LIST, yc.dataDir + yc.dataType)\n",
    "VAL_IMAGE_PATHS = yolo_utils.getImageAdresses(yc.VAL_IMAGE_LIST, yc.dataDir + yc.validationPath)\n",
    "\n",
    "imageDataset = yolo_utils.createImageDataset(IMAGE_PATHS)\n",
    "outputDataset = createOutputTensor(yc.IMAGE_LIST)\n",
    "image_output_ds = tf.data.Dataset.zip((imageDataset, outputDataset))\n",
    "\n",
    "image_output_ds = image_output_ds.batch(yc.BATCH_SIZE)\n",
    "image_output_ds = image_output_ds.prefetch(buffer_size=yc.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_Prediction_Output(y):\n",
    "    #Reshape label and prediction into 2 dimensions - (cell_count x parameter_count)\n",
    "    y = tf.reshape(y, [yc.CELL_COUNT, yc.COUNT_CLASSES + yc.COUNT_BOUNDING_BOXES*5])\n",
    "    class_values, box_values = tf.split(y, [yc.COUNT_CLASSES,yc.COUNT_BOUNDING_BOXES*5], -1)\n",
    "    \n",
    "    #2 confidence values per cell\n",
    "    box_values = tf.reshape(box_values, [yc.CELL_COUNT, yc.COUNT_BOUNDING_BOXES, 5])\n",
    "    box_values, confidence_values = tf.split(box_values, [4,1], -1)\n",
    "    \n",
    "    return class_values, box_values, confidence_values\n",
    "\n",
    "def reshape_Label(y):\n",
    "    #Reshape label and prediction into 2 dimensions - (cell_count x parameter_count)\n",
    "    y = tf.reshape(y, [yc.CELL_COUNT, yc.NUM_PARAMS_LABEL])\n",
    "    class_values, box_values = tf.split(y, [yc.COUNT_CLASSES,yc.COUNT_BOUNDING_BOXES*4], -1)\n",
    "    box_values = tf.reshape(box_values, [yc.CELL_COUNT, yc.COUNT_BOUNDING_BOXES, 4])\n",
    "    \n",
    "    return class_values, box_values\n",
    "\n",
    "def convert_Box_Parameters_IOU(box_values):\n",
    "    #create tensor for transformation into image-coordinates\n",
    "    #x-Axis values are created differently than y-Axis values\n",
    "    cells_x_Axis = tf.to_float(tf.range(yc.CELL_NUMBER_HORI)) * yc.CELL_WIDTH\n",
    "    cells_x_Axis = tf.broadcast_to(cells_x_Axis, [yc.COUNT_BOUNDING_BOXES, yc.CELL_COUNT])\n",
    "    cells_x_Axis = tf.transpose(cells_x_Axis)\n",
    "    cells_x_Axis = tf.reshape(cells_x_Axis, [yc.CELL_COUNT, yc.COUNT_BOUNDING_BOXES, 1])\n",
    "\n",
    "    cells_y_Axis = tf.to_float(tf.range(yc.CELL_NUMBER_VERT)) * yc.CELL_HEIGHT\n",
    "    cells_y_Axis = tf.broadcast_to(cells_y_Axis, [yc.CELL_NUMBER_VERT * yc.COUNT_BOUNDING_BOXES, yc.CELL_NUMBER_VERT])\n",
    "    cells_y_Axis = tf.transpose(cells_y_Axis)\n",
    "    cells_y_Axis = tf.reshape(cells_y_Axis, [yc.CELL_COUNT, yc.COUNT_BOUNDING_BOXES, 1])\n",
    "    \n",
    "    pos_x, pos_y, half_w, half_h = tf.split(box_values, [1, 1, 1, 1], -1)\n",
    "    \n",
    "    #convert positions into image-coordinates\n",
    "    pos_x *= yc.CELL_WIDTH\n",
    "    pos_x += cells_x_Axis\n",
    "    pos_y *= yc.CELL_HEIGHT\n",
    "    pos_y += cells_y_Axis\n",
    "    \n",
    "    #concat x and y positions to create tensor with all points in image-coordinates\n",
    "    pos = tf.concat([pos_x, pos_y], -1)\n",
    "    \n",
    "    \n",
    "    #convert width and height into image-coordinates\n",
    "    half_w *= yc.IMAGE_SIZE_WIDTH\n",
    "    half_h *= yc.IMAGE_SIZE_HEIGHT\n",
    "    \n",
    "    #concat width and height and divide by 2\n",
    "    half_wh = tf.concat([half_w, half_h], -1)\n",
    "    half_wh = tf.truediv(half_wh, 2.0)\n",
    "    \n",
    "    #get lower left point by subtracting half_wh from xy-positions -> (x - width * 0.5, y - height * 0.5)\n",
    "    box_location_min =  pos - half_wh\n",
    "    \n",
    "    #get upper right point by adding half_wh to xy-positions -> (x + width * 0.5, y + height * 0.5)\n",
    "    box_location_max = pos + half_wh\n",
    "    \n",
    "    return box_location_min, box_location_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Intersection_Area(box_min_label, box_max_label, box_min_pred, box_max_pred):\n",
    "    #the maximum of the minimum boxes is inside both boxes\n",
    "    intersection_max = tf.maximum(box_min_pred, box_min_label)\n",
    "    \n",
    "    #the minimum of the maximum boxes is inside both boxes\n",
    "    intersection_min = tf.minimum(box_max_pred, box_max_label)\n",
    "    \n",
    "    #if there is an intersection, min - max should be greater than 0\n",
    "    #by subtracting we no longer have xy-coordinates in the intersection-tensor stored, but width and height of the intersection\n",
    "    intersection = tf.maximum(intersection_min - intersection_max, 0.0)\n",
    "    \n",
    "    #calculate intersection area\n",
    "    intersection_a, intersection_b = tf.split(intersection, [1, 1], -1)\n",
    "    intersection_area = intersection_a * intersection_b\n",
    "    \n",
    "    return intersection_area\n",
    "\n",
    "def get_Union_Area(box_min_label, box_max_label, box_min_pred, box_max_pred, intersection_Area):\n",
    "    label_Area = box_max_label - box_min_label\n",
    "    \n",
    "    label_Area_a, label_Area_b = tf.split(label_Area, [1, 1], -1)\n",
    "    label_Area = label_Area_a * label_Area_b\n",
    "    \n",
    "    pred_Area = box_max_pred - box_min_pred\n",
    "    pred_Area_a, pred_Area_b = tf.split(pred_Area, [1, 1], -1)\n",
    "    pred_Area = pred_Area_a * pred_Area_b\n",
    "    pred_Area = tf.abs(pred_Area)\n",
    "    \n",
    "    union_Area = label_Area + pred_Area - intersection_Area\n",
    "    \n",
    "    image_Area = yc.IMAGE_SIZE_WIDTH * yc.IMAGE_SIZE_HEIGHT \n",
    "    union_Area = tf.clip_by_value(union_Area, 0.0, image_Area)\n",
    "    \n",
    "    return union_Area\n",
    "\n",
    "def calculate_IOU(box_values_label, box_values_pred):\n",
    "    #First: convert box-parameters for IOU-calculations - from (x, y, width, height) to (x1, y1, x2, y2)\n",
    "    box_min_label, box_max_label = convert_Box_Parameters_IOU(box_values_label)\n",
    "    box_min_pred, box_max_pred = convert_Box_Parameters_IOU(box_values_pred)\n",
    "    \n",
    "    #Second: calculate intersection area\n",
    "    intersection_Area = get_Intersection_Area(box_min_label, box_max_label, box_min_pred, box_max_pred)\n",
    "    \n",
    "    #Third: calculate union area\n",
    "    union_Area = get_Union_Area(box_min_label, box_max_label, box_min_pred, box_max_pred, intersection_Area)\n",
    "    \n",
    "    #Fourth: calculate Intersection over Union (IOU)\n",
    "    iou = tf.math.divide(intersection_Area, union_Area)\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate masks for iou and object identification. \n",
    "def calculate_Masks(iou, boxes):\n",
    "    #calculate iou-mask. Out of every box per cell only the box with the greatest iou value is responsible. \n",
    "    #Set the value of that box in iou-mask to 1. The other boxes are set to 0\n",
    "    #Multiply later with iou-mask so the loss will be set to 0 for every box not responsible\n",
    "    iou_box1, iou_box2 = tf.split(iou, [1, 1], -2)\n",
    "\n",
    "    zero = tf.zeros_like(iou_box1)\n",
    "    one = tf.ones_like(zero)\n",
    "    \n",
    "    iou_box1_new = tf.where(iou_box1 > iou_box2, one, zero)\n",
    "    iou_box2_new = one - iou_box1_new\n",
    "    iou_mask = tf.concat([iou_box1_new, iou_box2_new], -2)\n",
    "    \n",
    "    #calculate object-mask. If an object exists in that cell set the value to 1, otherwise 0\n",
    "    zero = tf.zeros_like(boxes)\n",
    "    one = tf.ones_like(boxes)\n",
    "    obj_mask = tf.where(tf.equal(boxes,0.), zero, one)\n",
    "    obj_mask = tf.reshape(obj_mask, [yc.CELL_COUNT, yc.COUNT_BOUNDING_BOXES, 1])\n",
    "\n",
    "    #calculate no-object-mask\n",
    "    noobj_mask = one - obj_mask\n",
    "\n",
    "    return iou_mask, obj_mask, noobj_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Position_Loss(label_x, label_y, pred_x, pred_y, mask):    \n",
    "    #calculate (xi − x^i)2 loss for every box and every cell\n",
    "    x_loss = tf.math.square(label_x - pred_x)\n",
    "    x_loss = tf.math.multiply(x_loss, mask)\n",
    "\n",
    "    #calculate (yi − y^i)2 loss for every box and every cell \n",
    "    y_loss = tf.math.square(label_y - pred_y)\n",
    "    y_loss = tf.math.multiply(y_loss, mask)\n",
    "    \n",
    "    #sum-up the loss for x and y coordinates (xi − x^i)2 + (yi − y^i)2\n",
    "    loss = tf.math.add(x_loss, y_loss)\n",
    "    \n",
    "    return tf.reduce_sum(loss)\n",
    "\n",
    "def calculate_Scalar_Loss(label_width, label_height, pred_width, pred_height, mask):\n",
    "    #make sure there are no 0 values in prediction tensors, because of sqrt-operation\n",
    "    zero = tf.zeros_like(pred_width)\n",
    "    pred_width = tf.where(pred_width < 0.0, zero, pred_width)\n",
    "    pred_height = tf.where(pred_height < 0.0, zero, pred_height)\n",
    "    sqrt_offset = tf.ones_like(pred_width)\n",
    "    sqrt_offset = sqrt_offset * 0.0001\n",
    "    pred_width = tf.where(tf.equal(pred_width, 0.0), sqrt_offset, pred_width)\n",
    "    pred_height = tf.where(tf.equal(pred_height, 0.0), sqrt_offset, pred_height)\n",
    "    \n",
    "    #calculate (sqrt(wi) − sqrt(w'i))2 loss for every box and every cell\n",
    "    w_loss = tf.math.square(tf.math.sqrt(pred_width) - tf.math.sqrt(label_width))\n",
    "    w_loss = tf.math.multiply(w_loss, mask)\n",
    "    \n",
    "    #calculate (sqrt(hi) − sqrt(h'i))2 loss for every box and every cell \n",
    "\n",
    "    h_loss = tf.math.square(tf.math.sqrt(pred_height) - tf.math.sqrt(label_height))\n",
    "    h_loss = tf.math.multiply(h_loss, mask)\n",
    "    \n",
    "    #sum-up the loss for width and height (sqrt(wi) − sqrt(w'i))2 + (sqrt(hi) − sqrt(h'i))2\n",
    "    loss = tf.math.add(w_loss, h_loss)\n",
    "\n",
    "    #sum all losses in a scalar value\n",
    "    return tf.reduce_sum(loss)\n",
    "\n",
    "def calculate_Confidence_Loss(iou, confidence_values_pred, obj_iou_mask, noobj_iou_mask):\n",
    "    loss = tf.math.square(iou - confidence_values_pred)\n",
    "    \n",
    "    #First: Calculate confidence loss for cells with objects\n",
    "    #check which cell and box are responsible for loss calculation. Boxes and cells that are not responsible are set to 0 loss value\n",
    "    obj_loss = tf.math.multiply(loss, obj_iou_mask)\n",
    "    \n",
    "    #Second: Calculate confidence loss for cells without objects\n",
    "    #check which cell and box are responsible for loss calculation. Boxes and cells that are not responsible are set to 0 loss value\n",
    "    noobj_loss = tf.math.multiply(loss, noobj_iou_mask)\n",
    "    #multiiply noobj loss with NO_OBJECT_LOSS_MULTIPLIER\n",
    "    noobj_loss *= yc.NO_OBJECT_LOSS_MULTIPLIER\n",
    "    \n",
    "    #sum-up the loss for cells with and without objects\n",
    "    loss = tf.math.add(obj_loss, noobj_loss)\n",
    "    \n",
    "    #sum all losses in a scalar value\n",
    "    return tf.reduce_sum(loss)\n",
    "\n",
    "def calculate_Class_Loss(class_values_label, class_values_pred):\n",
    "    #create a mask to ignore all cells without object\n",
    "    #Inside the cells with object every value is set to 1\n",
    "    mask = tf.reduce_max(class_values_label, -1)\n",
    "    mask = tf.reshape(mask, [yc.CELL_COUNT, 1])\n",
    "    mask = tf.tile(mask,[1, yc.COUNT_CLASSES])\n",
    "    \n",
    "    loss = tf.math.square(class_values_label - class_values_pred)\n",
    "    loss = tf.multiply(mask, loss)\n",
    "    \n",
    "    #sum all losses in a scalar value\n",
    "    return tf.reduce_sum(loss)\n",
    "\n",
    "def yoloLoss(label, prediction):\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    label = tf.squeeze(label)\n",
    "    prediction = tf.squeeze(prediction)\n",
    "    \n",
    "    #reshape and slice label and prediction tensors\n",
    "    class_values_label, box_values_label = reshape_Label(label)\n",
    "    class_values_pred, box_values_pred, confidence_values_pred = reshape_Prediction_Output(prediction)\n",
    "    \n",
    "    label_x, label_y, label_width, label_height  = tf.split(box_values_label, [1, 1, 1, 1], -1)\n",
    "    pred_x, pred_y, pred_width, pred_height  = tf.split(box_values_pred, [1, 1, 1, 1], -1)\n",
    "    \n",
    "    #calculate IOU for each box\n",
    "    iou = calculate_IOU(box_values_label, box_values_pred)\n",
    "    \n",
    "    #calculate 1-0-Masks\n",
    "    iou_mask, obj_mask, noobj_mask = calculate_Masks(iou, label_width)\n",
    "    obj_iou_mask = tf.math.multiply(iou_mask, obj_mask)\n",
    "    \n",
    "    \n",
    "    #calculate position loss\n",
    "    position_Loss = calculate_Position_Loss(label_x, label_y, pred_x, pred_y, obj_iou_mask)\n",
    "    #multiiply position loss with localisation loss multiplier\n",
    "    position_Loss *= yc.LOCALISATION_LOSS_MULTIPLIER\n",
    "    \n",
    "    #calculate scalar loss (height and width)\n",
    "    scalar_Loss = calculate_Scalar_Loss(label_width, label_height, pred_width, pred_height, obj_iou_mask)\n",
    "    #multiiply scalar loss with localisation loss multiplier\n",
    "    scalar_Loss *= yc.LOCALISATION_LOSS_MULTIPLIER\n",
    "    \n",
    "    #calculate confidence loss\n",
    "    noobj_iou_mask = tf.math.multiply(iou_mask, noobj_mask)\n",
    "    confidence_Loss = calculate_Confidence_Loss(iou, confidence_values_pred, obj_iou_mask, noobj_iou_mask)\n",
    "    \n",
    "    #calculate class loss\n",
    "    class_Loss = calculate_Class_Loss(class_values_label, class_values_pred)\n",
    "    \n",
    "    loss = tf.math.add_n([position_Loss, scalar_Loss, confidence_Loss, class_Loss])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programme\\Anaconda2\\envs\\yolo-env\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Programme\\Anaconda2\\envs\\yolo-env\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#recreate model from file\n",
    "model = tf.keras.models.load_model('.//yolo_v1.h5')\n",
    "\n",
    "#create a new model for training\n",
    "#model = yolo_utils.createYOLO_v1_Model(tiny = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0003)\n",
    "loss_history = []\n",
    "\n",
    "def train(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        loss_sum = 0.0\n",
    "        imagecount = 0\n",
    "        for (batch, (images, labels)) in enumerate(image_output_ds):\n",
    "            imagecount += 1\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = model(images, training=True)\n",
    "                loss_value = yoloLoss(labels, predictions)\n",
    "                loss_sum += loss_value\n",
    "\n",
    "            loss_history.append(loss_value.numpy())\n",
    "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables),global_step=tf.train.get_or_create_global_step())\n",
    "        print(\"loss_sum: \", loss_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-8bc94a279c09>:23: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "loss_sum:  tf.Tensor(54.151302, shape=(), dtype=float32)\n",
      "loss_sum:  tf.Tensor(55.338486, shape=(), dtype=float32)\n",
      "loss_sum:  tf.Tensor(56.06718, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.00003)\n",
    "train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('.//yolo_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the quality of the net. In this case the validation dataset is the same as the training dataset.\n",
    "#This is done because of bad results with the tiny YOLO version.  \n",
    "VAL_IMAGE_PATHS = yolo_utils.getImageAdresses(yc.VAL_IMAGE_LIST, yc.dataDir + yc.validationPath)\n",
    "val_Image_Dataset = yolo_utils.createImageDataset(VAL_IMAGE_PATHS)\n",
    "IOU_VALUE = 0.7\n",
    "\n",
    "def processPredictions(prediction, image, image_Number):\n",
    "    prediction = tf.squeeze(prediction)\n",
    "    image = tf.squeeze(image)\n",
    "    class_values_pred, box_values_pred, confidence_values_pred = reshape_Prediction_Output(prediction)\n",
    "    box_min_pred, box_max_pred = convert_Box_Parameters_IOU(box_values_pred)\n",
    "    confidence = confidence_values_pred.numpy()\n",
    "    tl = box_min_pred.numpy() \n",
    "    br = box_max_pred.numpy()\n",
    "    image = image.numpy() * 255.0\n",
    "    filename = \".//YOLO//\" + str(image_Number) + \".jpg\"\n",
    "    write = cv2.imwrite(filename,image)\n",
    "    \n",
    "    for cell in range(yc.CELL_COUNT):\n",
    "        for box in range(yc.COUNT_BOUNDING_BOXES):\n",
    "            if (confidence[cell][box][0] > IOU_VALUE):\n",
    "                pt1 = (tl[cell][box][0], tl[cell][box][1])\n",
    "                pt2 = (br[cell][box][0], br[cell][box][1])\n",
    "                image = cv2.rectangle(image, pt1, pt2, (200,0,0), 4)\n",
    "                if (class_values_pred[cell][0] > 0.5):\n",
    "                    image = cv2.putText(image, \"Cat\", pt1, cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)\n",
    "                if ( class_values_pred[cell][1] > 0.5):\n",
    "                    image = cv2.putText(image, \"Dog\", pt1, cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(filename,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check before training. Create images to check if image annotations are correctly transferred into the image\n",
    "def processLabels(labels, image, image_Number):\n",
    "    labels = tf.squeeze(labels)\n",
    "    image = tf.squeeze(image)\n",
    "    class_values, box_values = reshape_Label(labels)\n",
    "    box_values = tf.to_float(box_values)\n",
    "    box_min, box_max = convert_Box_Parameters_IOU(box_values)\n",
    "    tl = box_min.numpy() \n",
    "    br = box_max.numpy()\n",
    "    image = image.numpy() * 255.0\n",
    "    filename = \".//YOLO//\" + str(image_Number) + \".jpg\"\n",
    "    write = cv2.imwrite(filename,image)\n",
    "    \n",
    "    for cell in range(yc.CELL_COUNT):\n",
    "        for box in range(yc.COUNT_BOUNDING_BOXES):\n",
    "            pt1 = (tl[cell][box][0], tl[cell][box][1])\n",
    "            pt2 = (br[cell][box][0], br[cell][box][1])\n",
    "            image = cv2.rectangle(image, pt1, pt2, (200,0,0), 4)\n",
    "            if (class_values[cell][0] > 0.5):\n",
    "                image = cv2.putText(image, \"Cat\", pt1, cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)\n",
    "            if ( class_values[cell][1] > 0.5):\n",
    "                image = cv2.putText(image, \"Dog\", pt1, cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(filename,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-8bc94a279c09>:23: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "#Make predictions and test the neural net\n",
    "#Make sure there is a \"YOLO\"-directory in the directory of this notebook\n",
    "\n",
    "image_Number = 0\n",
    "for (batch, (image, labels)) in enumerate(image_output_ds):\n",
    "    prediction = model(image)\n",
    "    processPredictions(prediction, image, image_Number)\n",
    "    #processLabels(labels, image, image_Number)\n",
    "    image_Number += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
